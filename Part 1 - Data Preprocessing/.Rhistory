help.start()
x<-rnorm(50)
y<0rnorm(x)
y<rnorm(x)
x<-rnorm(50)
y<-rnorm(x)
x<-rnorm(50)
y<-rnorm(x)
y<-rnorm(x)
y<-rnorm(x)
plot(x,y)
clear
ls()
# Remove objects no longer needed.
x <- rnorm(50)
y <- rnorm(x)
ls()
summary(fm)
fm <- lm(y ~ x, data=dummy)
y-coordinates.
x <- rnorm(50)
y <- rnorm(x)
# Plot the points in a scatterplot
plot(x, y)
# See which R objects are now in the R workspace
ls()
# Remove objects no longer needed.
rm(x, y)
# Make x = (1, 2, 3, 4, . . . , 20).
x <- 1:20
# Create a 'weight' vector of standard deviations.
w <- 1 + sqrt(x)/2
# Make a data frame of two columns, x and y.
dummy <- data.frame(x=x, y= x + rnorm(x)*w)
# then take a look at it
dummy
# Fit a simple linear regression. With y to the left
# of the tilde, we are modelling y dependent on x.
fm <- lm(y ~ x, data=dummy)
# Look at the analysis
summary(fm)
#
search()#
q()
?rpart
?pamr
?knitr
?kernlab
?kernlab
a
q()
q()
load(swirl)
library(swirl)
swirl()
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
5 !== 7
5 != 7
!5 == 7
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor (5 == 6, !FALSE)
ints <- samples(10)
ints <- sample(10)
ints
ints > 5
which(ints > 7)
any(ints < 0)
all(ints > 0)
add2 <- function(x, y) {
x + y
}
add2(3,5)
add2(5,5)
x <- 1:20
above10 <- function(x) {
use <- x > 10
x[use]
}
above <- function(x, n) {
use <- x > n
x[use]
}
above(x, 10)
above10(x)
above <- function(x, n = 10) {
use <- x > n
x[use]
}
above(4)
above(x)
columnmean <- function(x){
nc <- ncol(x)
means <- numeric(x)
for (i in 1:nc){
means[i] <- mean(y[, i])
}
means
}
getwd()
library(readr)
hw1_data <- read_csv("C:/Users/Dan Siegel/Desktop/Classes/Data Science Course/2. Intro to R Programming/hw1_data.csv")
View(hw1_data)
columnmean(hw1_data)
columnmean(airquality)
hw1_data
columnmean <- function(x){
nc <- ncol(x)
means <- numeric(nc)
for (i in 1:nc){
means[i] <- mean(y[, i])
}
means
}
columnmean(hw1_data)
columnmean <- function(x){
nc <- ncol(x)
means <- numeric(nc)
for (i in 1:nc){
means[i] <- mean(x[, i])
}
means
}
columnmean(hw1_data)
columnmean(as.numeric(hw1_data)
columnmean(as.numeric(hw1_data))
columnmean(as.numeric(hw1_data[[1]]))
columnmean(as.numeric(hw1_data[1]))
columnmean(as.numeric(hw1_data[[1]]))
columnmean(hw1_data)
columnmean(hw1_data[1])
columnmean(as.numeric(hw1_data[1]))
columnmean(as.numeric(hw1_data[1]))
columnmean(as.numeric(as.character((hw1_data)))
columnmean(as.numeric(as.character((hw1_data))))
columnmean <- function(x, removeNA = TRUE){
nc <- ncol(x)
means <- numeric(nc)
for (i in 1:nc){
means[i] <- mean(x[, i], na.rm = removeNA)
}
means
}
columnmean(as.numeric(as.character((hw1_data))))
columnmean(as.numeric(hw1_data[, 1]))
columnmean(hw1_data[, 1])
columnmean(hw1_data[, Ozone])
columnmean(hw1_data$Ozone)
columnmean <- function(y, removeNA = TRUE){
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc){
means[i] <- mean(y[, i], na.rm = removeNA)
}
means
}
columnmean(hw1_data$Ozone)
sort(hw1_data$Ozone)
mean(hw1_data$Ozone)
test <- hw1_data$Ozone
mean(test)
mean(as.numeric(test)
mean(as.numeric(test))
mean(test, NA.rm = TRUE)
mean(as.numeric(test), NA.rm = TRUE)
mean(as.numeric(test), na.rm = TRUE)
means(as.numeric(hw1_data) na.rm = TRUE)
means(as.numeric(hw1_data), na.rm = TRUE)
columnmean(as.numeric(hw1_data), na.rm = TRUE)
columnmean(as.numeric(hw1_data))
columnmean(as.numeric(hw1_data$Ozone))
columnmean(as.numeric(hw1_data$Ozone), na.rm = TRUE)
q()
setwd("C:/Users/Dan Siegel/Desktop/Classes/Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing")
dataset = read.csv('Data.csv')
View(dataset)
View(dataset)
#missing datat
dataset$Age = ifelse(is.na(dataset$Age))
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm= TRUE)),
dataset$Age
)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm= TRUE)),
dataset$Salary
)
#Encode Categorical Data
dataset = read.csv('Data.csv')
#taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
> #Encode Categorical Data
dataset = read.csv('Data.csv')
#taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#Encode Categorical Data
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
View(dataset)
View(dataset)
View(dataset)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
#Encode Categorical Data
dataset$Country = factor(dataset$Country,
levels = c('France', 'Spain','Germany'),
labels = c(1,2,3))
dataset$Purchased = factor(dataset$Purchased,
levels = c('No', 'Yes'),
labels = c(0,1))
install.packages('caTools')
library("caTools", lib.loc="~/R/win-library/3.3")
detach("package:caTools", unload=TRUE)
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
split
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(training_set)
View(training_set)
View(test_set)
View(test_set)
#Feature Scaling
training_set = scale(training_set)
test_set = scale(test_set)
#Feature Scaling
training_set[, 2:3] = scale(training_set[, 2:3])
test_set[, 2:3] = scale(test_set[, 2:3])
